{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_features=50, n_redundant=0, n_informative=25, n_clusters_per_class=10, n_samples=5000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def defineParameters(jobs):\n",
    "    paramxgb = {\n",
    "        'silent': 1,\n",
    "        'objective': 'binary:logistic',  \n",
    "        'verbose': False,\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 8,\n",
    "        'nthread': jobs,\n",
    "        'min_child_weight': 100,\n",
    "    }\n",
    "\n",
    "    paramlgb = {\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 255,\n",
    "        'num_threads': jobs,\n",
    "        'min_data_in_leaf': 0,\n",
    "        'min_sum_hessian_in_leaf': 100,\n",
    "        'verbose': -1,\n",
    "        'metric': 'binary',\n",
    "    }\n",
    "\n",
    "    paramRf = {\n",
    "        'max_depth': 8,\n",
    "        'max_features': 50\n",
    "    }\n",
    "    return paramxgb, paramlgb, paramRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timeXGBoost():\n",
    "    print \"*** XGBoost ***\"\n",
    "    %timeit xgb.train(paramxgb, dtrain, training_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timeLightGBM():\n",
    "    print \"*** LightGBM ***\"\n",
    "    %timeit lgb.train(paramlgb, lgb_train, training_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timeRF():\n",
    "    print \"*** Random Forest ***\"\n",
    "    clf = RandomForestClassifier(max_depth=paramRf['max_depth'], max_features=paramRf['max_features'],random_state=0, n_estimators=training_iterations, n_jobs=jobs)\n",
    "    %timeit clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_iterations = 200  # the number of training iterations\n",
    "jobs = 1\n",
    "print \"*\" * 20 + \"  jobs = 1  \" + \"*\" * 20\n",
    "timeXGBoost()\n",
    "timeLightGBM()\n",
    "timeRF()\n",
    "\n",
    "jobs = 2\n",
    "print \"*\" * 20 + \"  jobs = 2  \" + \"*\" * 20\n",
    "timeXGBoost()\n",
    "timeLightGBM()\n",
    "timeRF()\n",
    "\n",
    "jobs = 4\n",
    "print \"*\" * 20 + \"  jobs = 4  \" + \"*\" * 20\n",
    "timeXGBoost()\n",
    "timeLightGBM()\n",
    "timeRF()\n",
    "\n",
    "jobs = 8\n",
    "print \"*\" * 20 + \"  jobs = 8 \" + \"*\" * 20\n",
    "timeXGBoost()\n",
    "timeLightGBM()\n",
    "timeRF()\n",
    "\n",
    "jobs = 16\n",
    "print \"*\" * 20 + \"  jobs = 16  \" + \"*\" * 20\n",
    "timeXGBoost()\n",
    "timeLightGBM()\n",
    "timeRF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
